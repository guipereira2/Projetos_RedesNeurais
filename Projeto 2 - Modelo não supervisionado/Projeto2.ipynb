{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Projeto 2 introdução a redes neurais - Modelo não supervisionado**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementar uma rede neural não supervisionada (e.g., SOM ou GNG) em pelo menos dois datasets, avaliar os padrões detectados em cada conjunto como custers e outliers. Avaliar a qualidade dos agrupamentos variando parâmetros como número de neurônios, taxas de aprendizado e grid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import os \n",
    "\n",
    "# Configuração do Searborn\n",
    "sns.set(\n",
    "    style='darkgrid',\n",
    "    context='notebook',\n",
    "    rc={\n",
    "        'axes.spines.top': False,\n",
    "        'axes.spines.right': False\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeiro Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro dataset é o Chest X-ray images (Pneumonia), é um dataset do *kaggle* (`https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia`) que contém 5856 imagens de raios-X de tórax, dividas em duas classes: pneumonia (bacteriana e viral) e sem pneumonia (normal). As imagens foram rotuladas manualmente.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As seguintes etapas serão realizadas: \n",
    " - Leitura das imagens: As imagens são divididas em pastas com as classes \"PNEUMONIA\" e \"NORMAL\".\n",
    " - Redimensionamento: Cada imagem é redimensionada para um tamanho fixo.\n",
    " - Transformação: As imagens são achatadas em vetores para o processamento da rede.\n",
    " - Codificação de rótulos: As classes são convertidas para valores binários.\n",
    " - Normalização dos dados: O conjunto de dados é escalado para garantir que todas as variáveis estejam na mesma escala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminhos para os dados de treino / teste \n",
    "\n",
    "diretorio_treino = \"./train\"\n",
    "diretorio_teste = \"./test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A biblioteca `os` será utilizada para navegar pelas pastas e acessar os arquivos. A função `os.listdir()` lista os arquivos dentro de um diretório especificado, enquanto `os.path.join()` é usada para construir caminhos de arquivos de maneira compatível com diferentes sistemas operacionais, garantindo a integridade do código em diferentes plataformas, já para a preparação das imagens a biblioteca OpenCV (cv2) será usada para carregar e pré-processar as imagens. A função `cv2.imread()` lê a imagem e a converte para escala cinza, enquanto `cv2.resize()` redimensiona todas as imagens para um tamanho uniforme. Em seguida, a imagem é achatada com o `img.flatten()` para transforma-lá em um vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para carregar e processar as imagens do dataset\n",
    "\n",
    "def carregar_imagens(diretorio, tamanho=(64, 64)): \n",
    "    \"\"\" \n",
    "    Função para carregar e preprocessar as imagens do diretório. \n",
    "    \n",
    "    Parâmetros: \n",
    "    - diretorio: Caminho para o diretório contendo as imagens.\n",
    "    - tamanho: Tamanho para o qual as imagens serão redimensionadas (64x64).\n",
    "    \n",
    "    Retorna: \n",
    "    - imagens: Array numpy com as imagens transformadas em vetores.\n",
    "    - rotulos_imagens: Array numpy com os rótulos (0 para \"NORMAL\" e 1 para \"PNEUMONIA\").\n",
    "    \"\"\"\n",
    "\n",
    "    # Listas para armazenar as imagens e seus respectivos rótulos\n",
    "    imagens = []\n",
    "    rotulos_imagens = []\n",
    "\n",
    "    # Loop para percorrer as pastas de imagens (\"PNEUMONIA\" e \"NORMAL\") dentro do diretório\n",
    "\n",
    "    for rotulo in os.listdir(diretorio): \n",
    "        pasta_rotulo = os.path.join(diretorio, rotulo)  # Caminho completo da pasta de rótulo\n",
    "        # Loop para percorrer os arquivos dentro da pasta de rótulo\n",
    "        for arquivo in os.listdir(pasta_rotulo): \n",
    "            caminho = os.path.join(pasta_rotulo, arquivo)  # Caminho completo da imagem\n",
    "            # Ler a imagem em escala cinza\n",
    "            imagem = cv2.imread(caminho, cv2.IMREAD_GRAYSCALE)\n",
    "            # Redimensionar a imagem\n",
    "            imagem = cv2.resize(imagem, tamanho)\n",
    "            # Achatar a imagem para um vetor\n",
    "            imagens.append(imagem.flatten())\n",
    "            # Codificação dos rótulos, 0 : NORMAL, 1 : PNEUMONIA\n",
    "            rotulos_imagens.append(0 if rotulo == \"NORMAL\" else 1)\n",
    "\n",
    "    # Retorna as imagens e os rótulos como arrays numpy\n",
    "    return np.array(imagens), np.array(rotulos_imagens) \n",
    "\n",
    "# Carregar as imagens de treino e teste usando a função 'carregar_imagens'\n",
    "dados_treino, labels_treino = carregar_imagens(diretorio_treino)\n",
    "dados_teste, labels_teste = carregar_imagens(diretorio_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A normalização dos dados será realizada utilizando o `MinMaxScaler`, que escala os valores para um intervalo específico. A fórmula utilizada para isso é: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "X_{\\text{escalado}} = \\frac{X - X_{\\text{min}}}{X_{\\text{max}} - X_{\\text{min}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em que: \n",
    "\n",
    "- $X$ é o valor original do dado.\n",
    "- $X_{\\text{min}}$ e $X_{\\text{max}}$ são, respectivamente, o menor e o maior valor da feature.\n",
    "- $X_{\\text{escalado}}$ é o valor normalizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler # Importando o MinMaxScaler\n",
    "# Criando uma instância do MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "dados_treino_normalizados = scaler.fit_transform(dados_treino) # Normalizar os dados de treino (escala entre 0 e 1)\n",
    "dados_teste_normalizados = scaler.transform(dados_teste) # Normalizar os dados de teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo neural não supervisionado self-organizing maps (SOM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`https://github.com/JustGlowing/minisom`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
